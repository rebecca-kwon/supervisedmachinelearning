{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/Generator/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/Generator/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction \n",
    "\n",
    "Predict forest model classifier would perform better due to classification and numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "x_train= pd.get_dummies(train_df.drop(columns=['target']))\n",
    "y_train=train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "x_test= pd.get_dummies(test_df.drop(columns=['target']))\n",
    "y_test=test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for col in x_train.columns:\n",
    "    if col not in x_test.columns:\n",
    "        x_test[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5089323692045938"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score (R2squared)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)\n",
    "classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6450446618460229"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score, \n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc better model for initial data, but neither performed very well.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "the forest model classifier performed better, confirming prediction rfc 64.5% > 51%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction \n",
    "\n",
    "Predict logistic regression model performs better due to the scaled data between data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data, -2 to +2 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "#### Prediction \n",
    "\n",
    "Predict forest model classifier would perform better due to classification and numerical data \n",
    "x_train_scaled=scaler.transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598894087622289"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(x_train_scaled, y_train)\n",
    "classifier2.score(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6473840918757975"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "rfc2=RandomForestClassifier()\n",
    "rfc2.fit(x_train_scaled, y_train)\n",
    "rfc2.score(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model performed better in the scaled data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "Logistic Regression model performed better as predicted, 76% > 65%, significantly performing better than the unscaled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata] *",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
